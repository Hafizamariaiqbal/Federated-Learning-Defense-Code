{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dcbb7a-4b18-42a4-9990-593ff3a132d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flwr torch torchvision scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ecc46c-b8c3-496d-a40c-4deeddb1bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1. Model Definition\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# 2. Flower Client\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, trainloader, testloader):\n",
    "        self.model = model\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for val in self.model.state_dict().values()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        self.model.load_state_dict({k: torch.tensor(v) for k, v in params_dict})\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=0.01)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        self.model.train()\n",
    "        for _ in range(2):  # Two local epochs\n",
    "            for data, target in self.trainloader:\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return self.get_parameters({}), len(self.trainloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total_loss = 0\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.testloader:\n",
    "                output = self.model(data)\n",
    "                loss = criterion(output, target)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += pred.eq(target).sum().item()\n",
    "                total_loss += loss.item() * data.size(0)\n",
    "        accuracy = correct / len(self.testloader.dataset)\n",
    "        avg_loss = total_loss / len(self.testloader.dataset)\n",
    "        print(f\"Eval: loss={avg_loss:.4f}, acc={accuracy*100:.2f}%\")\n",
    "        return float(avg_loss), len(self.testloader.dataset), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "# 3. Defense Aggregation on the Server\n",
    "def aggregate_with_defense(results, num_classes=10, k=2):\n",
    "    # Each result: (parameters, num_examples, metrics)\n",
    "    param_lists = [params[0] for params in results]\n",
    "    models = [torch.nn.utils.parameters_to_vector([torch.tensor(p) for p in params]) for params in param_lists]\n",
    "    models_stack = torch.stack(models)\n",
    "    # Output layer is last (fc2: 10*128)\n",
    "    output_layers = models_stack[:, -1280:].numpy().reshape(len(results), num_classes, 128)\n",
    "    honest_indices = set()\n",
    "    for c in range(num_classes):\n",
    "        kmeans = KMeans(n_clusters=min(k, len(results)), random_state=0).fit(output_layers[:, c, :])\n",
    "        labels, counts = np.unique(kmeans.labels_, return_counts=True)\n",
    "        honest_label = labels[np.argmax(counts)]\n",
    "        for i, l in enumerate(kmeans.labels_):\n",
    "            if l == honest_label:\n",
    "                honest_indices.add(i)\n",
    "    if not honest_indices:\n",
    "        honest_indices = set(range(len(results)))\n",
    "    honest_indices = sorted(list(honest_indices))\n",
    "    filtered_models = models_stack[honest_indices]\n",
    "    # Average model parameters among honest clients\n",
    "    avg_params_flat = filtered_models.mean(dim=0)\n",
    "    new_params = []\n",
    "    i = 0\n",
    "    # Use shapes from the first client\n",
    "    for v in param_lists[0]:\n",
    "        length = np.prod(v.shape)\n",
    "        new_params.append(avg_params_flat[i:i+length].reshape(v.shape).numpy())\n",
    "        i += length\n",
    "    print(\"Selected honest clients:\", honest_indices)\n",
    "    return new_params\n",
    "\n",
    "# 4. Data preparation\n",
    "def load_data(num_clients=5):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    testset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "    split_idx = np.array_split(np.arange(len(dataset)), num_clients)\n",
    "    trainloaders = [DataLoader(Subset(dataset, idx), batch_size=32, shuffle=True) for idx in split_idx]\n",
    "    testloader = DataLoader(testset, batch_size=128)\n",
    "    return trainloaders, testloader\n",
    "\n",
    "def client_fn(cid):\n",
    "    model = SimpleNet()\n",
    "    trainloaders, testloader = load_data()\n",
    "    return FlowerClient(model, trainloaders[int(cid)], testloader)\n",
    "\n",
    "# 5. Start Flower Simulation\n",
    "if __name__ == \"__main__\":\n",
    "    num_clients = 5\n",
    "    num_rounds = 5\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,\n",
    "        min_fit_clients=num_clients,\n",
    "        min_available_clients=num_clients,\n",
    "        on_aggregate_fit=lambda r: aggregate_with_defense(r, num_classes=10),\n",
    "    )\n",
    "    fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=num_clients,\n",
    "        config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
    "        strategy=strategy,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d3642-de5f-4c3f-90fb-cab00cf0c2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
